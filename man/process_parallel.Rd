% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/process_parallel.r
\docType{methods}
\name{process_parallel}
\alias{process_parallel}
\alias{process_parallel,Catalog-method}
\title{Apply a function to a set of tiles using several cores.}
\usage{
process_parallel(x, func, platform = .Platform$OS.type,
  mc.cores = parallel::detectCores(), combine = "rbind", varlist = "")

\S4method{process_parallel}{Catalog}(x, func, platform = .Platform$OS.type,
  mc.cores = parallel::detectCores(), combine = "rbind", varlist = "")
}
\arguments{
\item{x}{A Catalog object}

\item{func}{A function which has one parameter: the name of a .las or .laz file (see example)}

\item{platform}{charater. Can be "windows" or "unix". Default is autodetect. See sections "Details", "Unix" and  "Windows".}

\item{mc.cores}{integer. Number of cores used. Default is the number of cores you have on your computer.}

\item{combine}{character. The function used to merge the outputs of the \code{func} function.}

\item{varlist}{charaters vector. For windows mode, character vector of names of objects to export.}
}
\description{
The function has different behaviours on MS Windows and Unix platform, read carfully
the doc, sections "Detail", "Unix" and "Windows". This function provide an immediatly usable
parallel computing tool but users confortable with multi-core process are better
to use there own code to have a more flexible tools.
}
\details{
When users have a set of LAS data organized in several tiles it can apply a user function to each tile.
Examples section describes the procedure to apply to each file beginning with data loading (see example).
The function automatically detect you operating system and apply the best parallelisation method for your system.
Unix mechanism is more powerfull. However it is not compatible with Windows (see sections Unix and Windows).
The Windows mechanism is more complex to use.\cr\cr
WARNING: there is no buffer mechanism to protect the process again edge artifacs. See section "Edge artifacts".
}
\section{Unix}{


In Unix platform (GNU/Linux and Mac), the parallelization rely on fork-exec technique
(see \link[parallel:mclapply]{mclapply}). It means, among others, that each child process
has an acces to the parent process' memory. For example you can call functions from .GlobalEnv
or any orther environnement. If a code written for Unix is ran on Windows it will works
but with only one core like a normal loop. If Unix users want to share their code
to Windows users they are better to force the function to use clustering method.
}

\section{Windows}{


In Windows platform (MS Windows), the parallelization rely on cluster
(see \link[parallel:parLapplyLB]{parLapplyLB}). It works both for Unix and Windows
but it is much more memory intensive and very not userfriendly as the user must
export himself all the object he needs. Indeed cluster technique implies, among others,
that each child process cannot acces to the parent process memory.
If you want to make the process on 1 core only, use the \code{unix} mode which work simpler
on windows when using only one core (non parallel computing).
}

\section{Egde artifacts}{


It is very important to take precautions to avoid "edge artifacts" when processing LiDAR tiles.
If the points from neighboring tiles are not included during certain process it might involve edge artifacts
at the edges of the tiles. For exemple, empty or incomplete pixels in a rasterization process. The lidR package
does not provide internal tools to deal with buffer as it is design for experimental purposes not to output professional
products. The users could, for example, filter the invalid/corrupted data at the edge of the tiles from the output.
}
\examples{
\dontrun{
# Visit http://jean-romain.github.io/lidR/catalog.html for more examples
# about this function

# 1. build a project
project = Catalog("folder")
plot(project)

# 2. load the shapefile you need to filter your points (if needed).
lake = rgdal::readOGR("folder", "shapefile")

# 3 build the function which analyses a tile (a file).
# This function input is only the path of a .las file
# see the following template

analyse_tile = function(LASFile)
{
  # Load the data
  lidar = readLAS(LASFile)

  # Associate geographic data with lidar points (if needed)
  lidar \%<>\% classifyFromShapefile(lake, field="inlake")

  # filter lake
  lidar \%<>\% lasfilter(lake == FALSE)
  # compute all metrics
  metrics = gridMetrics(lidar, 20, myMetrics(X,Y,Z,Intensity,ScanAngle,pulseID))

  return(metrics)
}
#### UNIX #####
# This code works only on Unix platforms because it rely on shared memory
# between all the process. See below for a Windows compatible code.

# 4. Process the project. By default it detects how many cores you have. But you can add
# an optional parameter mc.core = 3.
output = project \%>\% process_parallel(analyse_tile)

#### WINDOWS #####
# This code works both on Unix and Windows platforms. But it is more memory intensive
# and more complex (here the exemple is simple enought so it does not change a lot of things)

# 4. Process the project. By default it detects how many cores you have. But you can add
# an optional parameter mc.core = 3.
export = c("readLAS", "classifyFromShapefile", "gridMetrics",
           "myMetrics", "lake", "lasfilter", "\%<>\%")
output = project \%>\% process_parallel(analyse_tile, varlist = export, platform = "windows")
}
}
\seealso{
\link[lidR:Catalog-class]{catalog}
\link[parallel:mclapply]{mclapply}
\link[parallel:parLapplyLB]{parLapplyLB}
\link[lidR:classifyFromShapefile]{classifyFromShapefile}
\link[lidR:gridMetrics]{gridMetrics}
}

