% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/catalog_apply.r
\name{catalog_apply}
\alias{catalog_apply}
\title{Apply a user defined function to an entire catalog}
\usage{
catalog_apply(ctg, func, ...)
}
\arguments{
\item{func}{A function which has one parameter: the name of a .las or .laz file (see example)}

\item{x}{A \link[lidR:catalog]{Catalog} object}
}
\description{
This function enable to apply a user defined routine over an entiere catalog using a multi-core
process. When a user has a dataset organized into several files, it applies a user defined
function to the entiere catalog by automatically splitting the catalog into several clusters.
The clustering pattern can be either split as a set of squared areas or can be split by file.
The clustering pattern can be modified using the global catalog options with \link{catalog_options}.
The "Examples" section describes the procedure to apply functions to the catalog, beginning
with data loading (see example). \cr\cr
\strong{Warning:} there is a buffer mechanism to load buffered data and to avoid edge artifacts
but no mechnism to remove the buffer after applying the user defined functions since this task.
is very specific to each process. See section "Edge artifacts".
}
\section{Edge artifacts}{


It is very important to take precautions to avoid 'edge artifacts' when processing LiDAR
tiles. If the points from neighboring tiles are not included during certain processes,
this could create 'edge artifacts' at the edges of the tiles. For example, empty or incomplete
pixels in a rasterization process. The lidR package provides internal tools to load buffered
data. However there is not mechanism to remove the results computed in the buffered area
since this task depends on the output of the user defined function. Therefore, depending
on what the user is computing some outputs results can appear several time.\cr\cr
The LAS object received by the user defined function has a special colum called 'buffer_side'
which enable, for each point, to know if the point comes from a buffered areas or not. Points
from not buffered areas have a 'buffer_side' of zero while points from buffered areas have
a 'buffer_side' of 1, 2, 3 or 4. 1 being the bottom buffer and 2, 3 and 4 being respectively
the left, top and right buffer (see example).
}

\examples{
# Visit http://jean-romain.github.io/lidR/wiki for more examples
# about this function

# 1. build a project (here a single tiny file catalog for the need of example)
folder <- system.file("extdata", "", package="lidR")
project = catalog(folder)
project = project[1,]
plot(project)

# 2. set some global catalog options
# For the need of this dummy example the clustering size is 80 m and the buffer is 10 m using
# a single core.
catalog_options(by_file = FALSE, buffer = 10, multicore = 1, tiling_size = 80)

# 3. load the shapefile you need to filter your points.
lake_shp = rgdal::readOGR(folder, "lake_polygons_UTM17")

# 4. build the function which analyses a cluster of the catalog.
# This function first argument is a LAS object. See the following template:
myAnalyse = function(las, lake)
{
  # Associate geographic data with lidar points
  lasclassify(las, lake, field = "lake")

  # filter lakes, and low elevation points
  las \%<>\% lasfilter(lake == FALSE, Z > 4)

  # segment trees (in this example the low point density does not enable
  # to segment tree properly. This is just a proof of concept)
  lastrees(las, algorithm = "li2012")

  # count the trees
  num_tree = length(unique(las@data$treeID))

  return(num_tree)
}

# 4. Process the project.
output = catalog_apply(project, myAnalyse, lake = lake_shp)

# 5. Post process the output results (depend of what is the output)
output = unlist(output)
total_trees = sum(output)
}
